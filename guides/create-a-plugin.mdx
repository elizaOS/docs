---
title: 'Create a Plugin'
description: 'Build a text-to-video plugin from scratch - create, test locally, and prepare for sharing'
---

<Note>
Want comprehensive plugin development documentation? Check out our [Plugin Development Guide](/plugins/plugin-development-guide) for advanced patterns and best practices.
</Note>

## What We'll Build

Today we're creating a **text-to-video plugin** using fal.ai that can generate 6-second videos from text descriptions. You'll learn the complete journey from local development to preparing for distribution.

**By the end, your agent will be able to:**
- Generate videos from text prompts like "a dolphin dancing in the ocean"
- Process requests in 30-60 seconds using the MiniMax Hailuo-02 model
- Return 768p resolution videos ready for sharing

---

## Step 1: Create the Plugin

Let's start by scaffolding a new plugin using the elizaOS CLI:

<Steps>
  <Step title="Create the plugin">
    ```bash Terminal
    elizaos create --type plugin fal-ai
    cd plugin-fal-ai
    ```
    
    This creates a complete plugin structure with TypeScript configuration, build tools, and example components ready to customize.
  </Step>

  <Step title="Check dependencies">
    The plugin already includes all necessary dependencies:
    
    ```json package.json
    "dependencies": {
      "@elizaos/core": "latest",
      "@fal-ai/serverless-client": "^0.15.0"
    }
    ```
    
    Everything is ready to go - no additional installation needed!
  </Step>

  <Step title="Get your fal.ai API key">
    1. Visit [fal.ai](https://fal.ai) and create an account
    2. Go to [Dashboard ‚Üí Keys](https://fal.ai/dashboard/keys)
    3. Create a new API key and copy it (you'll need this for testing)
    
    <Note>
    fal.ai offers a generous free tier perfect for testing. Video generation costs about $0.25 per 6-second video.
    </Note>
  </Step>
</Steps>

---

## Step 2: Build the Text-to-Video Action

Now let's create the core functionality - an action that converts text to video.

### Create the action file

```typescript src/actions/generateVideo.ts
import { 
  Action,
  ActionResult,
  IAgentRuntime, 
  Memory, 
  HandlerCallback,
  State,
  logger
} from '@elizaos/core';
import { fal } from '@fal-ai/client';

export const generateVideoAction: Action = {
  name: 'TEXT_TO_VIDEO',
  similes: ['CREATE_VIDEO', 'MAKE_VIDEO', 'GENERATE_VIDEO', 'VIDEO_FROM_TEXT'],
  description: 'Generate a video from text using MiniMax Hailuo-02 (768p resolution, 6-second videos)',
  
  validate: async (runtime: IAgentRuntime, message: Memory) => {
    const falKey = runtime.getSetting('FAL_KEY');
    if (!falKey) {
      logger.error('FAL_KEY not found in environment variables');
      return false;
    }
    return true;
  },
  
  handler: async (
    runtime: IAgentRuntime,
    message: Memory,
    state: State | undefined,
    options: any,
    callback?: HandlerCallback
  ): Promise<ActionResult> => {
    try {
      // Configure fal.ai client
      fal.config({
        credentials: runtime.getSetting('FAL_KEY')
      });
      
      // Extract prompt from message
      let prompt = message.content.text;
      
      // Remove common prefixes
      prompt = prompt
        .replace(/^(text to video:|create video:|make video:|generate video:|video:)/i, '')
        .trim();
      
      if (!prompt) {
        const errorMessage = "I need a description for the video. Try: 'Create video: a dolphin dancing in the ocean'";
        return {
          text: errorMessage,
          success: false
        };
      }
      
      logger.info(`Generating video with prompt: ${prompt}`);
      
      // Call fal.ai API using the subscribe pattern for real-time updates
      const result = await fal.subscribe("fal-ai/minimax/hailuo-02/standard/text-to-video", {
        input: {
          prompt: prompt,
          duration: "6", // 6-second videos
          prompt_optimizer: true
        },
        logs: true,
        onQueueUpdate: (update: any) => {
          if (update.status === "IN_PROGRESS") {
            logger.info(`Video generation progress: ${update.status}`);
          }
        }
      });
      
      if (!result.data.video || !result.data.video.url) {
        throw new Error('No video returned from fal.ai');
      }
      
      const videoUrl = result.data.video.url;
      const responseText = `‚úÖ Video generated! View it here: ${videoUrl}

(Note: Click the link to open the video - videos don't embed due to browser security)`;
      
      return {
        text: responseText,
        success: true,
        data: {
          videoUrl,
          prompt,
          duration: "6 seconds"
        }
      };
      
    } catch (error) {
      logger.error('Video generation failed:', error);
      const errorMessage = `Failed to generate video: ${error instanceof Error ? error.message : String(error)}`;
      
      return {
        text: errorMessage,
        success: false,
        error: error instanceof Error ? error : new Error(String(error))
      };
    }
  },
  
  examples: [
    [
      {
        name: 'user',
        content: { text: 'Create video: a galactic smuggler navigating through space' }
      },
      {
        name: 'assistant', 
        content: { 
          text: "I'll create a 6-second video of a galactic smuggler navigating through space!",
          action: 'TEXT_TO_VIDEO'
        }
      }
    ],
    [
      {
        name: 'user',
        content: { text: 'Generate video: dolphins jumping in crystal clear ocean water' }
      },
      {
        name: 'assistant',
        content: {
          text: '‚úÖ Video generated! View it here: https://fal.ai/files/video123.mp4',
          action: 'TEXT_TO_VIDEO'
        }
      }
    ]
  ]
};
```

### Export the action in your plugin

Update your main plugin file to include the new action:

```typescript src/index.ts
import { Plugin, IAgentRuntime } from '@elizaos/core';
import { textToVideoAction } from './actions/textToVideo';

export const falAIPlugin: Plugin = {
  name: 'fal-ai',
  description: 'Generate videos and images using fal.ai AI models',
  
  actions: [textToVideoAction],
  
  async init(runtime: IAgentRuntime) {
    // Check for API key during initialization
    const apiKey = runtime.getSetting('FAL_KEY');
    if (!apiKey) {
      console.warn('‚ö†Ô∏è FAL_KEY not found in environment variables');
      console.warn('   Add your fal.ai API key to use video generation features');
    } else {
      console.log('‚úÖ fal.ai plugin initialized successfully');
    }
  }
};

export default falAIPlugin;
```

---

## Step 3: Test Your Plugin Locally

Before publishing, let's test the plugin in a real project. There are **two ways** to load plugins - we'll use the direct import method for local testing.

<Steps>
  <Step title="Create a test project">
    ```bash Terminal
    cd ..
    elizaos create my-video-agent --type project
    cd my-video-agent
    ```
    
    Choose your preferred options:
    - **Database**: PgLite (perfect for local testing)
    - **Model**: OpenAI or Anthropic
    - **Plugins**: Keep the defaults for now
  </Step>

  <Step title="Import the plugin directly">
    **Method 1: Direct Import (Local Development)**
    
    Open `src/index.ts` and add your plugin:
    
    ```typescript src/index.ts
    import { logger, type IAgentRuntime, type Project, type ProjectAgent } from '@elizaos/core';
    import { character } from './character.ts';
    import falaiPlugin from '../plugin-fal-ai/dist/index.js';  // [!code ++]
    
    export const projectAgent: ProjectAgent = {
      character,
      init: async (runtime: IAgentRuntime) => await initCharacter({ runtime }),
      plugins: [starterPlugin, falaiPlugin],  // [!code ++]
      tests: [ProjectStarterTestSuite],
    };
    ```
    
    <Note>
    **No `bun add` needed!** Direct imports work perfectly for local development and testing.
    </Note>
    
    <Info>
    **Method 2: Character Plugins Array** (for published plugins)
    
    After your plugin is published to npm, users would add it like this:
    ```typescript src/character.ts
    export const character: Character = {
      plugins: [
        '@elizaos/plugin-sql',
        '@elizaos/plugin-bootstrap', 
        '@your-username/plugin-fal-ai' // After npm publish
      ],
    };
    ```
    </Info>
  </Step>

  <Step title="Add your API key">
    ```bash Terminal
    elizaos env edit-local
    ```
    
    Add your fal.ai API key to the `.env` file:
    ```env .env
    FAL_KEY=your_actual_fal_key_here
    ```
    
    <Tip>
    The agent uses `runtime.getSetting('FAL_KEY')` to access this securely, so the variable name must match exactly.
    </Tip>
  </Step>

  <Step title="Build and test the plugin">
    ```bash Terminal
    # Build the plugin first
    cd ../plugin-fal-ai
    bun run build
    
    # Go back and start the agent
    cd ../my-video-agent  
    elizaos start
    ```
    
    <Warning>
    **Always run `bun run build`** after making changes to your plugin! The direct import uses the compiled code from `/dist/`.
    </Warning>
  </Step>

  <Step title="Test video generation">
    Visit `http://localhost:3000` and try these commands:
    
    - `"Create video: a dolphin dancing in the ocean"`
    - `"Generate video: a fluffy cat playing piano"`
    - `"Text to video: sunset over mountains"`
    
    You should see:
    1. **"üé¨ Starting video generation..."** (immediate acknowledgment)
    2. **"Video generation progress: IN_PROGRESS..."** (progress update)  
    3. **"‚úÖ Video generated successfully! View it here: [URL]"** (final result)
    
    <Note>
    **Videos return as URLs** due to browser security (CSP). Click the links to view your generated videos! This works perfectly in Discord and Telegram where media embeds properly.
    </Note>
  </Step>
</Steps>

---

## Step 4: Prepare for Publishing

Ready to share your plugin with the world? Let's prepare it for npm publication.

### Update package.json

```json package.json
{
  "name": "@your-username/plugin-fal-ai",  // Add YOUR npm username
  "version": "0.1.0",
  "description": "Generate videos from text using fal.ai - 768p, 6-second videos with MiniMax Hailuo-02",
  "keywords": ["elizaos-plugin", "fal-ai", "video-generation", "text-to-video", "ai"],
  "author": "Your Name <your.email@example.com>",
  "repository": "github:your-username/plugin-fal-ai",
  "agentConfig": {
    "actions": ["TEXT_TO_VIDEO"],
    "providers": [],
    "evaluators": [],
    "models": ["gpt-4", "claude-3", "anthropic"],
    "services": []
  }
}
```

### Build for distribution

```bash Terminal
cd ../plugin-fal-ai
bun run build
```

<Tip>
**Want to publish immediately?** Check out our [Publish a Plugin](/guides/publish-a-plugin) guide for the complete publishing workflow including npm, GitHub, and registry submission.
</Tip>

---

## Step 5: Test the Full Workflow

Let's verify everything works end-to-end:

### Complete test scenario

1. **Start your test project:**
   ```bash Terminal
   cd ../my-video-agent
   elizaos start
   ```

2. **Generate a test video:**
   - Go to `http://localhost:3000`
   - Type: `"Create video: a fluffy character eating ice cream that's melting"`
   - Wait 30-60 seconds for generation
   - Click the returned URL to view your video

3. **Check the logs:**
   ```
   ‚úì fal.ai plugin loaded
   üé¨ Starting video generation: "a fluffy character eating ice cream that's melting"
   Video generation progress: IN_PROGRESS
   ‚úÖ Video generated successfully!
   ```

<Warning>
**Common Issues:**
- **Plugin not loading?** Did you run `bun run build`?
- **FAL_KEY not found?** Check your `.env` file has the correct variable name
- **Videos won't embed?** That's normal browser security - click the links to view
- **Action not triggering?** Use exact phrases like `"Create video:"`
</Warning>

---

## Understanding Plugin Loading Methods

Your plugin now supports **two loading patterns** that users can choose from:

### For Local Development
```typescript src/index.ts
// Direct import - perfect for testing and development
import falaiPlugin from '../plugin-fal-ai/dist/index.js';

export const projectAgent: ProjectAgent = {
  plugins: [starterPlugin, falaiPlugin], // Add directly
};
```

**Benefits:**
- ‚úÖ No `bun add` needed
- ‚úÖ Perfect for iteration and testing  
- ‚úÖ Works with relative paths
- ‚úÖ See changes immediately after `bun run build`

### For Published Plugins  
```typescript src/character.ts
export const character: Character = {
  plugins: [
    '@elizaos/plugin-bootstrap',
    '@your-username/plugin-fal-ai' // npm package name
  ],
};
```

**Benefits:**
- ‚úÖ Users install with `elizaos plugins add @your-username/plugin-fal-ai`
- ‚úÖ Automatic version management
- ‚úÖ Part of the elizaOS ecosystem
- ‚úÖ Discoverable in the plugin registry

---

## Step 6: Enhance Your Plugin

Want to make your plugin even better? Here are some ideas:

### Add More Models

```typescript src/actions/textToVideo.ts
// Add support for different models
const models = {
  'minimax': 'fal-ai/minimax-video',
  'stable-video': 'fal-ai/stable-video-diffusion',
  'runway': 'fal-ai/runway-gen3'
};

// Let users choose the model
const modelType = extractModelFromPrompt(prompt) || 'minimax';
const result = await fal.run(models[modelType], { prompt });
```

### Add Image-to-Video

```typescript src/actions/imageToVideo.ts
export const imageToVideoAction: Action = {
  name: 'IMAGE_TO_VIDEO',
  description: 'Convert an image into a video animation',
  
  validate: async (runtime, message) => {
    return message.content.text?.includes('animate image') ||
           message.content.attachments?.some(a => a.type === 'image');
  },

  handler: async (runtime, message, state, options, callback) => {
    // Extract image URL and animate it
    const imageUrl = extractImageUrl(message);
    
    const result = await fal.run('fal-ai/stable-video-diffusion', {
      image_url: imageUrl,
      motion_bucket_id: 127
    });
    
    return {
      success: true,
      text: `üé¨ Image animated! View: ${result.video_url}`,
      data: { videoUrl: result.video_url, sourceImage: imageUrl }
    };
  }
};
```

### Add Configuration Options

```typescript src/actions/textToVideo.ts
// Let users customize video settings
const settings = {
  duration: runtime.getSetting('FALAI_VIDEO_DURATION') || 6,
  aspectRatio: runtime.getSetting('FALAI_ASPECT_RATIO') || '16:9',
  quality: runtime.getSetting('FALAI_QUALITY') || 'standard'
};
```

---

## What's Next?

<CardGroup cols={2}>
  <Card title="Publish a Plugin" icon="upload" href="/guides/publish-a-plugin">
    Share your text-to-video plugin with the elizaOS community
  </Card>
  <Card title="Plugin Development Guide" icon="code" href="/plugins/plugin-development-guide">
    Learn advanced patterns: services, providers, evaluators, and more
  </Card>
  <Card title="Test a Project" icon="flask" href="/guides/test-a-project">
    Write comprehensive tests for your plugin
  </Card>
  <Card title="Add Multiple Agents" icon="users" href="/guides/add-multiple-agents">
    Create a team of agents that can all generate videos
  </Card>
</CardGroup>

## Quick Reference

**Plugin Commands:**
```bash
elizaos create --type plugin fal-ai    # Create plugin
bun run build                          # Build after changes  
elizaos start                          # Test in project
elizaos publish --test                 # Test publishing
elizaos publish                        # Publish for real
```

**Trigger Phrases:**
- "Create video: [description]"
- "Generate video: [description]"  
- "Text to video: [description]"
- "Make video: [description]"

**Features:**
- üé• 768p resolution videos
- ‚è±Ô∏è 6-second duration  
- ü§ñ MiniMax Hailuo-02 model
- ‚ö° 30-60 second generation time
- üí∞ ~$0.25 per video

**Loading Methods:**
- **Local:** Direct import in `index.ts` (no npm install)
- **Published:** Add to `character.plugins` array (after npm publish)

Remember: Build something useful, test it thoroughly, and the elizaOS community will love your contribution! üöÄ
